\documentclass[conference]{IEEEtran}

\IEEEoverridecommandlockouts

\usepackage[nomain, acronym, symbols]{glossaries}
\usepackage[english]{babel}
\usepackage[numbers]{natbib}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{caption}
\usepackage{dblfloatfix}
\usepackage{cleveref}

\loadglsentries{acronyms}

\begin{document}

\title{Fine-tuning of LLaMA for Skin Lesion Classification and Medical Report Generation}

\author{
    \IEEEauthorblockN{1\textsuperscript{st} Eric Fernandes Evaristo}
    \IEEEauthorblockA{
        \textit{Dept. of \acrlong{ine}} \\
        \textit{\acrlong{ufsc}} \\
        Florianópolis, Brazil \\
        eric.f.evaristo@posgrad.ufsc.br
    }
\and
    \IEEEauthorblockN{2\textsuperscript{nd} Aldo von Wangenheim}
    \IEEEauthorblockA{
        \textit{Dept. of \acrlong{ine}} \\
        \textit{\acrlong{ufsc}} \\
        Florianópolis, Brazil \\
        aldo.vw@ufsc.br
    }
\and
    \IEEEauthorblockN{3\textsuperscript{rd} Rodrigo de Paula e Silva Ribeiro}
    \IEEEauthorblockA{
        \textit{Dept. of \acrlong{ine}} \\
        \textit{\acrlong{ufsc}} \\
        Florianópolis, Brazil \\
        ribeiro.rodrigo@posgrad.ufsc.br
    }
}

\maketitle

\begin{abstract}
    The early detection of skin lesions is crucial for the treatment of severe diseases, such as skin cancer. However, these lesions are usually only diagnosed by dermatologists. Given that these professionals are not always available in regions with less healthcare infrastructure, it would be useful to have a tool capable of skin lesion classification and medical report generation. For this purpose, we fine-tuned \gls{llama} 3.2 11B with \gls{qlora} and \gls{lora}. The fine-tuning was performed in two scenarios, in the first scenario, we trained the model with the \gls{ham10000} dataset for classification tasks only, achieving an accuracy of up to 86.2\% with \gls{lora}. In the second scenario, the model was trained with the \gls{sttsc} dataset for both classification and report generation. The final models presented a classification accuracy of 45.2\% with \gls{qlora} and 44.5\% with \gls{lora}. This low performance can be explained by inconsistencies in the \gls{sttsc} dataset.
\end{abstract}

\begin{IEEEkeywords}
    Skin Lesions, Skin Cancer, \acrshort{mllm}, \gls{llama}, Fine-tuning, \gls{qlora}, \gls{lora}.
\end{IEEEkeywords}

\section{Introduction}

Skin lesions are symptoms of several diseases, most notably skin cancer. In Brazil, skin cancer is particularly relevant, accounting for 30\% of all malignant tumors \cite{skin_cancer_in_brazil}. Accurate and early classification of the lesion category is fundamental for adequate treatment. However, this is a complex task dependent on many visual aspects, thus requiring analysis by trained professionals, such as dermatologists \cite{habif2015clinical, skin_cancer_survival}.

The early detection of skin cancer also has a socio-economic factor. As noted in studies by \citet{skin_cancer_socioeconomic} and \citet{santos2020desigualdades}, patients who present with tumors in more advanced stages tend to come from a lower socio-economic background. This can be correlated with a lack of access to specialized healthcare and dermatologists for these patients. However, in the Brazilian context, primary healthcare is partially provided by \gls{acs} (Community Health Agents), who offer basic health assistance and are in direct contact with impoverished communities \cite{filgueiras2011agente}.

In this context, a user-friendly tool capable of classifying skin lesions and generating reports would be useful, as it could be used by \gls{acs} as a screening mechanism, thereby addressing the lack of access to dermatologists for part of the population. The requirements for such a tool could be addressed by a \gls{mllm}. Therefore, \gls{llama}-3.2-11B was chosen as the base model in this work for the experimental development of a skin lesion classifier and report generator.

The development was divided into two scenarios. In the first, the model was fine-tuned with the \gls{ham10000} dataset. In the second scenario, the model was fine-tuned with the \gls{sttsc} dataset. Both scenarios employed \gls{qlora} and \gls{lora}.

\subsection{Contributions}

The following contributions are presented in this work:

\begin{itemize}
    \item The development of a fine-tuned version of \gls{llama}-3.2-11B capable of classifying skin lesions and generating reports.
    \item A comparative analysis of the fine-tuned models with the base model.
    \item A comparative analysis of the efficiency of \gls{qlora} and \gls{lora} in fine-tuning.
\end{itemize}

\section{Basic Concepts}

This section defines the basic concepts applied in this research.

\subsection{Skin Lesion Images}

Skin lesion images can be classified into different categories. The procedures described by \citet{fotos_dermatologia} for obtaining these images present three categories: dermatoscopy, close-up and panoramic images. For the fine-tuning, only dermatoscopy and close-up images were used.

Dermatoscopy images are obtained with a dermatoscope, which is used to capture an image of the specific area of skin where the lesion is. Alternatively, close-up images can be obtained with a regular camera and a ruler, where they are used to take a picture of the region of the body where the skin lesion appears with a distance of 30cm from the skin lesion to the camera. \autoref{fig:skin_lesion_exams} presents examples of exams with the categories of images utilized in this work.

\begin{figure}[htbp]
\centerline{\includegraphics{figures/skin_lesion_exams.png}}
\caption{Example of a dermatoscopy (left) and a close-up (right) exam. Source: \citet{fotos_dermatologia}}
\label{fig:skin_lesion_exams}
\end{figure}

\subsection{Multimodal Large Language Models}

\glspl{mllm} are generative \gls{ai} models based on \glspl{llm} that are capable of processing information from multiple modalities, such as images, audio, and text. For the interpretation of multimodal data, \glspl{mllm} have modality encoders, which are integrated with the \gls{llm} through an input projector. Furthermore, \glspl{llm} and most modality encoders are based on transformers \cite{mllm_survey_2024}.

\subsection{Fine-tuning}

Fine-tuning can be defined as a training procedure with the objective of adapting a pre-trained model for a specific task or domain. With \gls{peft} techniques, such as \gls{qlora} and \gls{lora}, the process can be much less computationally intensive than full-parameter fine-tuning \cite{llm_survey_2023}.

The \gls{lora} method was introduced by \citet{hu2021lora}, utilizing the intrinsic rank of matrices. It introduces smaller trainable matrices while freezing the original model matrices during training, greatly reducing the amount of tunable parameters. After training, the smaller matrices can be added to the original ones, resulting in a fine-tuned model.

In order to further reduce the computational cost, \citet{qlora} introduced \gls{qlora}, a quantized version of \gls{lora}. With this method, low-precision numerical data types such as \gls{nf4} and \gls{bf16} are used.

\section{Related Works}

Over the past years, several papers have demonstrated applications of \glspl{mllm} to the analysis of medical images. In a systematic literature review, \citet{eric2025systematic} highlights the main advancements in this field. Overall, most \glspl{mllm} are generalist, operating over several medical domains. However, some models such as SkinGPT-4 and MpoxVLM focus on dermatological tasks \cite{zhou2023skingpt,cao2024mpoxvlm}.

What distinguishes this work from others is the utilization of \gls{llama}-3.2-11B, since other models focused on dermatology are still based on older \glspl{mllm}. Furthermore, a comparative analysis of \gls{qlora} and \gls{lora} in fine-tuning has not been presented in the existing literature.

\section{Methodology and Developement}

The following subsections will present the development scenarios. The resulting models from the first scenario were not utilized in the second one. This Methodology was implemented for a better assessment of the efficiency of different fine-tuning methods. The trainings were conducted with a NVIDIA H100 on a NVIDIA DGX H100 platform and with the framework Unsloth.

\subsection{First Scenario}

The first scenario is comprised of the fine-tuning of the base model with different dataset sizes and fine-tuning parameters. \gls{ham10000} was utilized as the dataset, it contains 13,354 dermatoscopy images with a resolution of \(600 \times 450\) pixels. This dataset is split between training, test and validation sections, with 9,577, 1,258 and 2,492 images, respectively. For the fine-tuning, the dataset was adapted to a conversational structure, where the user asks for the skin lesion classification in the image and the model answers accordingly.

\gls{llama}-3.2-11B was fine-tuned with 450, 900 and 5,000 samples from the training dataset. The hyperparameters were based on recommended values by Unsloth documentation. For each sample size, a \gls{qlora} and \gls{lora} were used.

\subsection{Second Scenario}

In the second scenario, the base model was fine-tuned with the \gls{sttsc} dataset. This dataset was created through the sanitization and structuring of a set of 31,243 close-up images and 3,651 exams, resulting in a dataset with 4,736 samples for training and 1,167 samples for testing. Each sample consists of a pair of a close-up image with the highest resolution dimension scaled to 1024 pixels and a medical report with the skin lesion classification, a risk classification, a conclusion field with recommendations and a brief diagnostic. The data was also structured in a conversational pattern, where the user presents an image and asks for its information, requesting it to filled with a specific template and the model answers as required.

Here, the fine-tuning was initially performed only with \gls{qlora} in order to find ideal hyperparameters more efficiently. In total, eight models were trained with variations on the rank, \(\alpha_{\gls{lora}}\) and number of epochs. Besides, the hyperparameters were adjusted according to recommendations from \citet{tribes2023hyperparameter} and the Unsloth documentation. The resulting model with the highest accuracy in skin lesion classification was fine-tuned with a rank and \(\alpha_{\gls{lora}}\) of 128 and 3 epochs. These hyperparameters were then used for the fine-tuning with \gls{lora}.

\section{Results and Discussion}

\subsection{Tests}

The results were collected through an automated testing process. Each fine-tuned model from the first scenario was prompted with 1,000 questions, each including an image from the test section of the \gls{ham10000} dataset. The models were configured with a temperature of 0.1 and their answers were limited to 128 tokens.

% This is in the bottom of the second page, it's weird, I know.
\begin{figure*}[b]
    \centering
    \includegraphics[width=1.0\textwidth,keepaspectratio]{figures/metrics_comparison_graph.png}
    \caption{\gls{nlp} metrics over the generated reports for the base model and the fine-tuned models.}
    \label{fig:nlp_metrics}
\end{figure*}

For the second scenario, both fine-tuned models were prompted with 1,167 questions using data from the test section of the \gls{sttsc} dataset. The temperature used was 0.005, with answers limited to 2190 tokens.

\subsection{Performance in Skin Lesion Classification}

The results for skin lesion classification indicate that models fine-tuned with close-up images achieved a undesirable performance. This accuracy is considerably lower than that of the models from the first scenario, which were fine-tuned with dermatoscopy images.

The models from the first scenario achieved superior results even with significantly smaller training volumes. For instance, the \gls{qlora} model trained on only 450 dermatoscopy images (65.5\%) outperformed the \gls{qlora} model trained on 4,736 close-up images (45.2\%).

Furthermore, when comparing the largest datasets, the \gls{qlora} model with 5,000 dermatoscopy images (85.4\%) surpassed the \gls{qlora} model with 4,736 close-up images (45.2\%) by 40.2\%. \autoref{tab:overall_comparison_skin_lesions} shows the accuracy for each fine-tuned model.

\begin{table}[ht]
    \centering
    \begin{tabular}{l|l|c|c}
        \hline
        Image category                  & Fine-tuning method & Dataset size & Accuracy (\%) \\ \hline
        \multirow{10}{*}{Dermatoscopy} & None (Quantized)            & -                     & 11,8 \\
                                        & None                         & -                     & 14,0 \\ \cline{2--2}
                                        & \multirow{3}{*}{\gls{qlora}}    & 450                   & 65,5 \\
                                        &                                & 900                   & 65,2 \\
                                        &                                & 5000                  & 85,4 \\ \cline{2--2}
                                        & \multirow{3}{*}{\gls{lora}}     & 450                   & 49,5 \\
                                        &                                & 900                   & 42,0 \\
                                        &                                & 5000                  & \textbf{86,2} \\ \hline
        \multirow{4}{*}{close-up}    & None (Quantized)            & -                     & 14,8 \\
                                        & None                         & -                     & 17,0 \\ \cline{2--2}
                                        & \gls{qlora}                     & 4736                  & \textbf{45,2} \\ \cline{2--2}
                                        & \gls{lora}                      & 4736                  & 44,5 \\ \hline
    \end{tabular}
    \caption{Accuracy in the classification of skin lesions. The highest values are highlighted in bold.}
    \label{tab:overall_comparison_skin_lesions}
\end{table}

\subsection{Performance in Risk Classification}

The risk classification, introduced only in the second scenario, showed an unsatisfactory performance, with the highest accuracy of 55.1\% being achieved by the model trained with \gls{lora}. \autoref{tab:overall_comparison_risk} presents the accuracy in the risk classification for the fine-tuned models of the second scenario.

\begin{table}[ht]
    \centering
    \begin{tabular}{l|c}
        \hline
        Fine-tuning method & Accuracy (\%) \\ \hline
        None (Quantized)            & 23,4          \\
        None                         & 27,4          \\
        \gls{qlora}                     & 54,6          \\
        \gls{lora}                      & \textbf{55,1} \\ \hline
    \end{tabular}
    \caption{Accuracy in the risk classification for the second scenario. The highest values are highlighted in bold.}
    \label{tab:overall_comparison_risk}
\end{table}

\subsection{Performance in Report Generation}

The performance in report generation was evaluated with three \gls{nlp} metrics: \gls{bleu}, \gls{rouge}, and \gls{meteor}. The results indicate that the fine-tuned models perform much better than the base model in this task. Both the models trained with \gls{qlora} and \gls{lora} successfully generalized the report format, presenting recommendations in a manner similar to a real dermatologist. The greatest improvement was observed with the \gls{bleu} and \gls{meteor} metrics. \autoref{fig:nlp_metrics} depicts the \gls{nlp} metrics for the models.

The reports generated by \gls{llama}-3.2-11B followed the specified template and used appropriate medical language, but they failed to provide the expected recommendations. However, the reports generated by the fine-tuned models also presented some problems, such as the presence of grammatical errors, which may be explained by errors in the source dataset itself.

\subsection{Comparison between QLoRA and LoRA}

Lastly, when comparing the training metrics presented in \Cref{fig:duration,fig:memory} and \autoref{tab:final_training_metrics}, we noticed that both fine-tuning methods require similar amounts of time to complete. Furthermore, \gls{lora} tends to allocate more memory. In the first scenario, \gls{lora} had an average memory utilization 84.19\% greater than \gls{qlora}. In the second scenario, \gls{lora} used 25.94\% more memory.

This discrepancy in memory utilization between the first and second scenarios can be explained by changes in hyperparameters that affect memory usage, such as the device batch size and the gradient accumulation steps. Moreover, dataset-specific aspects can also influence memory utilization.

\begin{figure}[htb]
    \centering
    \includegraphics[width=1.0\columnwidth,keepaspectratio]{figures/Fine-tuning Duration.pdf}
    \caption{Fine-tuning duration in the first scenario for different dataset sizes.}
    \label{fig:duration}
\end{figure}

\begin{figure}[htb]
    \centering
    \includegraphics[width=1.0\columnwidth,keepaspectratio]{figures/Memory Utilization.pdf}
    \caption{Memory utilization in the first scenario for different dataset sizes.}
    \label{fig:memory}
\end{figure}

\begin{table}[ht]
    \centering
    \begin{tabular}{l|c|c}
        \hline
        Fine-tuning method & Duration (min) & Memory utilization (GB) \\ \hline
        \gls{qlora}            & 286,83                     & 47,57                  \\
        \gls{lora}             & 276,46                     & 59,91                  \\ \hline
    \end{tabular}
    \caption{Training metrics for both methods in the second scenario.}
    \label{tab:final_training_metrics}
\end{table}

\section{Conclusion}

The presented results found that the fine-tuning of the \gls{llama}-3.2-11B model can be done efficiently through training with \gls{qlora}. The models trained with this method achieved performance similar to that of models trained with \gls{lora} and required less memory during training.

The results of the second scenario were unsatisfactory regarding the lesion classification criterion, reaching an accuracy of only 45.2\% after the fine-tuning with \gls{qlora}. Although the volume of data used in this scenario was similar to the larger volumes of the first scenario. The data volume in the training set may have been insufficient for fine-tuning, making it hard for the final models to perform a complex task such as generating reports with classifications and recommendations. In addition to the insufficient volume, the dataset imbalance, characterized by the rarity of some lesions, may have impacted the trained models, leading to lower performance in classifying lesions with few occurrences in the dataset. Another negative aspect of the set was the variability within some lesion classes, specially in classes that represent undefined lesions. The large volume of uncertain classes may have led to the low performance observed in the classification tasks.

The performance in generating the conclusion texts in the final stage was reasonably satisfactory. However, some problems were identified, such as spelling errors and non-ideal formatting. These characteristics also stem from inconsistencies and errors in the dataset.

\subsection{Future work}

Considering the results and limitations identified in this project, we propose the construction of a new dataset with greater volume and consistency between classes. It would also be necessary to include a new class referring to healthy cases, as the model is currently fine-tuned to classify only different skin lesions, disregarding the possibility of the absence of lesions.

In-depth optimization of training hyperparameters is also recommended, possibly using grid search techniques.

The use of other \glspl{mllm} is also recommended, particularly Gemma 3 by \citet{team2025gemma}. This would make it possible to conduct a more advanced comparison between the different models.

Finally, we also suggest the use of manual evaluations on parts of the test results. Currently, the results are analyzed automatically, which can lead to the disregard of important aspects of the generated text. With the participation of qualified dermatologists, it would be possible to evaluate the content of these texts in greater depth.

\section{Conclusion}

The presented results show that the \gls{llama}-3.2-11B model can be efficiently fine-tuned through training with \gls{qlora}. The models trained with this method achieved performance similar to those trained with \gls{lora} and required less memory during training.

The results of the second scenario were unsatisfactory regarding the lesion classification criterion, reaching an accuracy of only 45.2\% after fine-tuning with \gls{qlora}, despite the data volume being similar to the largest volume of the first scenario. The data volume in the training set may have been insufficient for fine-tuning, making it difficult for the final models to perform a complex task such as generating reports with classifications and recommendations. In addition to the insufficient volume, dataset imbalance, characterized by the rarity of some lesions, may have impacted the trained models, leading to lower performance in classifying lesions with few occurrences in the dataset. Another negative aspect of the set was the variability within some lesion classes, especially in classes that represent undefined lesions. The large volume of uncertain classes may have contributed to the low performance observed in the classification tasks.

The performance in generating the reports in the final stage was reasonably satisfactory. However, some problems were identified, such as spelling errors and non-ideal formatting. These characteristics also appear to stem from inconsistencies and errors in the dataset.

\subsection{Future work}

Considering the results and limitations identified in this project, we propose the construction of a new dataset with greater volume and consistency between classes. It would also be necessary to include a new class referring to healthy cases, as the model is currently fine-tuned to classify only different skin lesions, disregarding the possibility of the absence of lesions.

In-depth optimization of training hyperparameters is also recommended, possibly using grid search techniques.

The use of other \glspl{mllm} is also recommended, particularly Gemma 3 by \citet{team2025gemma}. This would make it possible to conduct a more advanced comparison between the different models.

Finally, we also suggest the use of manual evaluation of parts of the test results. Currently, the results are analyzed automatically, which can lead to disregarding important aspects of the generated text. With the participation of qualified dermatologists, it would be possible to evaluate the content of these texts in greater depth.

\bibliographystyle{IEEEtranN}
\bibliography{references}

\clearpage

\onecolumn

\section*{Links}

\begin{itemize}
    \item \textbf{Link para a publicação original (TCC)}: \url{https://repositorio.ufsc.br/handle/123456789/266618}
    \item \textbf{Link alternativo}: \url{https://github.com/ErFer7/LLaDerm/releases/download/TCC-Final/TCC.-.Final.pdf}
\end{itemize}

\section*{Modificações}

Um gráfico de barras foi criado para as métricas de \gls{nlp}, substituindo a tabela no trabalho original. Melhorando a visualização comparativa das métricas.

\end{document}

